{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8938295-1e65-4325-b254-6bae9336072f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayso\\AppData\\Local\\Temp\\ipykernel_6488\\1708540394.py:89: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f73ea\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f73ea_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f73ea_level0_col1\" class=\"col_heading level0 col1\" >Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f73ea_level0_row0\" class=\"row_heading level0 row0\" >7</th>\n",
       "      <td id=\"T_f73ea_row0_col0\" class=\"data row0 col0\" >Decision Tree</td>\n",
       "      <td id=\"T_f73ea_row0_col1\" class=\"data row0 col1\" >88.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f73ea_level0_row1\" class=\"row_heading level0 row1\" >8</th>\n",
       "      <td id=\"T_f73ea_row1_col0\" class=\"data row1 col0\" >Random Forest</td>\n",
       "      <td id=\"T_f73ea_row1_col1\" class=\"data row1 col1\" >88.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f73ea_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f73ea_row2_col0\" class=\"data row2 col0\" >KNN</td>\n",
       "      <td id=\"T_f73ea_row2_col1\" class=\"data row2 col1\" >85.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f73ea_level0_row3\" class=\"row_heading level0 row3\" >1</th>\n",
       "      <td id=\"T_f73ea_row3_col0\" class=\"data row3 col0\" >Support Vector Machines</td>\n",
       "      <td id=\"T_f73ea_row3_col1\" class=\"data row3 col1\" >83.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f73ea_level0_row4\" class=\"row_heading level0 row4\" >0</th>\n",
       "      <td id=\"T_f73ea_row4_col0\" class=\"data row4 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_f73ea_row4_col1\" class=\"data row4 col1\" >81.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f73ea_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f73ea_row5_col0\" class=\"data row5 col0\" >Linear SVC</td>\n",
       "      <td id=\"T_f73ea_row5_col1\" class=\"data row5 col1\" >80.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f73ea_level0_row6\" class=\"row_heading level0 row6\" >3</th>\n",
       "      <td id=\"T_f73ea_row6_col0\" class=\"data row6 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_f73ea_row6_col1\" class=\"data row6 col1\" >76.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f73ea_level0_row7\" class=\"row_heading level0 row7\" >6</th>\n",
       "      <td id=\"T_f73ea_row7_col0\" class=\"data row7 col0\" >Stochastic Gradient Decent</td>\n",
       "      <td id=\"T_f73ea_row7_col1\" class=\"data row7 col1\" >66.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f73ea_level0_row8\" class=\"row_heading level0 row8\" >4</th>\n",
       "      <td id=\"T_f73ea_row8_col0\" class=\"data row8 col0\" >Perceptron</td>\n",
       "      <td id=\"T_f73ea_row8_col1\" class=\"data row8 col1\" >64.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d4df20ba10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Import Libraries ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from IPython.display import display\n",
    "\n",
    "# === Load Data ===\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "# === Drop Unused Columns ===\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "# === Extract Titles from Names ===\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# === Map Titles to Integers ===\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "# === Drop Name & PassengerId ===\n",
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "# === Convert Sex to Numeric ===\n",
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
    "\n",
    "# === Fill Missing Age Using RandomForest Regressor ===\n",
    "for dataset in combine:\n",
    "    age_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare']\n",
    "    known_age = dataset.dropna(subset=['Age'])\n",
    "    unknown_age = dataset[dataset['Age'].isnull()]\n",
    "    if unknown_age[age_features].isnull().values.any():\n",
    "        age_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "        ])\n",
    "        age_pipeline.fit(known_age[age_features], known_age['Age'])\n",
    "        predicted_ages = age_pipeline.predict(unknown_age[age_features])\n",
    "        dataset.loc[dataset['Age'].isnull(), 'Age'] = predicted_ages\n",
    "    dataset['Age'] = dataset['Age'].astype(float).round().astype('Int64')\n",
    "\n",
    "# === Bin Age into Categories ===\n",
    "for dataset in combine:\n",
    "    dataset['Age'] = pd.cut(dataset['Age'], bins=[0, 16, 32, 48, 64, np.inf],\n",
    "                            labels=[0, 1, 2, 3, 4], include_lowest=True).astype(float).round().astype('Int64')\n",
    "\n",
    "# === Create FamilySize and IsAlone ===\n",
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "# === Drop SibSp, Parch, FamilySize ===\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "# === Feature: Age*Class ===\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset['Age'] * dataset['Pclass']\n",
    "\n",
    "# === Fill Embarked ===\n",
    "freq_port = train_df['Embarked'].dropna().mode()[0]\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "\n",
    "# === Fill missing Fare and Bin into Quartiles ===\n",
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
    "for dataset in combine:\n",
    "    dataset['Fare'] = pd.qcut(dataset['Fare'], 4, labels=[0, 1, 2, 3]).astype(int)\n",
    "\n",
    "# === Prepare for Training ===\n",
    "X_train = train_df.drop('Survived', axis=1)\n",
    "Y_train = train_df['Survived']\n",
    "X_test = test_df.drop('PassengerId', axis=1).copy()\n",
    "\n",
    "# === Impute any leftover missing values (just in case) ===\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# === Train and Score Multiple Models ===\n",
    "models = []\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_imputed, Y_train)\n",
    "models.append(('Logistic Regression', round(logreg.score(X_train_imputed, Y_train) * 100, 2)))\n",
    "\n",
    "svc = SVC(gamma='auto')\n",
    "svc.fit(X_train_imputed, Y_train)\n",
    "models.append(('Support Vector Machines', round(svc.score(X_train_imputed, Y_train) * 100, 2)))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_imputed, Y_train)\n",
    "models.append(('KNN', round(knn.score(X_train_imputed, Y_train) * 100, 2)))\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train_imputed, Y_train)\n",
    "models.append(('Naive Bayes', round(gaussian.score(X_train_imputed, Y_train) * 100, 2)))\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train_imputed, Y_train)\n",
    "models.append(('Perceptron', round(perceptron.score(X_train_imputed, Y_train) * 100, 2)))\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train_imputed, Y_train)\n",
    "models.append(('Linear SVC', round(linear_svc.score(X_train_imputed, Y_train) * 100, 2)))\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train_imputed, Y_train)\n",
    "models.append(('Stochastic Gradient Decent', round(sgd.score(X_train_imputed, Y_train) * 100, 2)))\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train_imputed, Y_train)\n",
    "models.append(('Decision Tree', round(decision_tree.score(X_train_imputed, Y_train) * 100, 2)))\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train_imputed, Y_train)\n",
    "models.append(('Random Forest', round(random_forest.score(X_train_imputed, Y_train) * 100, 2)))\n",
    "\n",
    "# === Show Model Comparison Table ===\n",
    "models_df = pd.DataFrame(models, columns=['Model', 'Score'])\n",
    "models_sorted = models_df.sort_values(by='Score', ascending=False)\n",
    "display(models_sorted.style.format({'Score': '{:.2f}'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00607f-1f8e-4a13-845c-d0129c792288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
